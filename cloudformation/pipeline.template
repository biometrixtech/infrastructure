# A template that creates the processing pipeline for biometric data
#
# Copyright 2017 Melon Software Ltd (UK), all rights reserved
#
AWSTemplateFormatVersion: "2010-09-09"
Description: "Creates a pre-processing pipeline"

Parameters:

    Environment:
        Type: "String"
        Description: "The name of the Environment"

    BatchJobVersionDownloadandchunk:
        Type: "String"
        Description: "The version of the downloadandchunk batch job to run"
    BatchJobVersionSessionprocess2:
        Type: "String"
        Description: "The version of the sessionprocess2 batch job to run"
    BatchJobVersionNoop:
        Type: "String"
        Description: "The version of the `noop` batch job to run"
    BatchJobVersionScoring:
        Type: "String"
        Description: "The version of the `scoring` batch job to run"
    BatchJobVersionDatabaseupload:
        Type: "String"
        Description: "The version of the `databaseupload` batch job to run"

Metadata:
    "AWS::CloudFormation::Interface":
        ParameterGroups:
          - Label: { default: "Environment" }
            Parameters:
              - "Environment"
          - Label: { default: "Batch Jobs" }
            Parameters:
              - "BatchJobVersionDownloadandchunk"
              - "BatchJobVersionSessionprocess2"
              - "BatchJobVersionNoop"
              - "BatchJobVersionScoring"
              - "BatchJobVersionDatabaseupload"

        ParameterLabels:
            Environment: { default: "Environment" }
            BatchJobVersionDownloadandchunk: { default: "downloadandchunk" }
            BatchJobVersionSessionprocess2: { default: "sessionprocess2" }
            BatchJobVersionNoop: { default: "noop" }
            BatchJobVersionScoring: { default: "scoring" }
            BatchJobVersionDatabaseupload: { default: "databaseupload" }

Resources:

    ##########################################################################################################
    ##  IAM
    ##########################################################################################################

    LambdaExecutionRole:
        Type: "AWS::IAM::Role"
        Properties:
            AssumeRolePolicyDocument:
                Version: "2012-10-17"
                Statement:
                  - Effect: "Allow"
                    Principal: { Service: [ "lambda.amazonaws.com" ] }
                    Action: "sts:AssumeRole"
            ManagedPolicyArns:
              - "arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole"
            Policies:
              - PolicyName: "default"
                PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Action:
                          - "logs:CreateLogGroup"
                          - "logs:CreateLogStream"
                          - "logs:PutLogEvents"
                        Effect: "Allow"
                        Resource: "*"

                      - Action:
                          - "sns:Publish"
                          - "lambda:InvokeFunction"
                          - "states:StartExecution"
                        Effect: "Allow"
                        Resource: "*"

                      - Action:
                          - "ssm:DescribeParameters"
                          - "ssm:GetParameters"
                          - "kms:Decrypt"
                        Effect: "Allow"
                        Resource:
                          - "*" # TODO this should be segregated by environment somehow
            RoleName: { "Fn::Sub": "preprocessing-${Environment}-lambda" }

    ##########################################################################################################
    ##  LAMBDA
    ##########################################################################################################

    LambdaPrepareDownloadAndChunk:
        Type: "AWS::Lambda::Function"
        Properties:
            Code:
                ZipFile: !Sub |
                    def handler(event, context):
                        return {
                            "Meta": {
                                "ActivityArn": "${StepFunctionsActivity}",
                                "ExecutionArn": event['Meta']['ExecutionArn'],
                                "Environment": "${Environment}"
                            },
                            "Branches": [
                                {
                                    "Resource": {
                                        "BatchJobQueue": "arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-queue/preprocessing-${Environment}-compute",
                                        "BatchJobDefinition": "arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-definition/preprocessing-batchjob${BatchJobVersionDownloadandchunk}",
                                        "BatchJob": "downloadandchunk"
                                    },
                                    "InputPath": "$"
                                }
                            ],
                            "Input": event['SourceEvent']
                        }
            Handler: "index.handler"
            Runtime: "python3.6"
            Timeout: "30"
            Role: { "Fn::GetAtt" : [ "LambdaExecutionRole", "Arn" ] }
            FunctionName: { "Fn::Sub": "preprocessing-${Environment}-pipeline-prepare-downloadandchunk" }

    LambdaReadPostgres:
        Type: "AWS::Lambda::Function"
        Properties:
            Code:
                ZipFile: !Sub |
                    import boto3, json
                    lambda_client = boto3.client('lambda', region_name='us-west-2')
                    def invoke(query, parameters):
                        res = json.loads(lambda_client.invoke(
                            FunctionName='arn:aws:lambda:us-west-2:887689817172:function:preprocessing-dev-pipeline-querypostgres',
                            Payload=json.dumps({"Queries": [{"Query": query, "Parameters": parameters}]}),
                        )['Payload'].read())
                        result, error = res['Results'][0], res['Errors'][0]
                        if error is not None:
                            raise Exception(error)
                        else:
                            return result[0] if len(result) else {}

                    def handler(event, context):
                        query_results = query(
                            """SELECT
                              session_events.id AS session_event_id,
                              session_events.training_session_log_id,
                              session_events.hip_n_transform,
                              training_session_logs.training_group_id,
                              session_events.user_id,
                              users.weight,
                              training_groups.team_id,
                              session_events.session_type
                            FROM session_events
                            LEFT JOIN training_session_logs ON session_events.training_session_log_id=training_session_logs.id
                            LEFT JOIN users ON session_events.user_id=users.id
                            LEFT JOIN training_groups ON training_session_logs.training_group_id=training_groups.id
                            WHERE session_events.sensor_data_filename = %s""",
                            [event['SourceEvent']['S3Path']]
                        )
                        ret = {
                            "SessionEventId": query_results.get('session_event_id', None),
                            "TrainingSessionLogId": query_results.get('training_session_log_id', None),
                            "HipNTransform": query_results.get('hip_n_transform', None),
                            "TrainingGroupId": query_results.get('training_group_id', None),
                            "UserId": query_results.get('user_id', None),
                            "UserWeight": query_results.get('weight', None),
                            "TeamId": query_results.get('team_id', None),
                            "SessionType": query_results.get('session_type', None),
                        }
                        res = json.loads(lambda_client.invoke(
                            FunctionName='arn:aws:lambda:us-west-2:887689817172:function:preprocessing-dev-pipeline-querypostgres',
                            Payload=json.dumps({"Queries": [{
                                "Query": "select * from fn_get_sensor_data_filename_hist((%s))",
                                "Parameters": [res['UserId']]
                            }]}),
                        )['Payload'].read())['Results']
                        query_results = res[0][0] if len(res[0]) else {}
                        res["HistoricalFiles"] = query_results
                        return res

            Handler: "index.handler"
            Runtime: "python3.6"
            Timeout: "30"
            Role: { "Fn::GetAtt" : [ "LambdaExecutionRole", "Arn" ] }
            FunctionName: { "Fn::Sub": "preprocessing-${Environment}-pipeline-readpostgres" }

    LambdaPrepareSessionProcess2:
        Type: "AWS::Lambda::Function"
        Properties:
            Code:
                ZipFile: !Sub |
                    def handler(event, context):
                        return {
                            "Meta": {
                                "ActivityArn": "${StepFunctionsActivity}",
                                "ExecutionArn": event['Meta']['ExecutionArn'],
                                "Environment": "${Environment}",
                                "NoopJobDefinition": "arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-definition/preprocessing-batchjob${BatchJobVersionNoop}"
                            },
                            "Branches": [
                                {
                                    "Resource": {
                                        "BatchJobQueue": "arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-queue/preprocessing-${Environment}-compute",
                                        "BatchJobDefinition": "arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-definition/preprocessing-batchjob${BatchJobVersionSessionprocess2}",
                                        "BatchJob": "sessionprocess2"
                                    },
                                    "InputPath": "$[{}]".format(i)
                                }
                                for i in range(len(event['DownloadAndChunkOutput'][1]['Output']['Filenames']))
                            ],
                            "Input": [
                                {**event["ReadDatabaseOutput"], **{"Filename": f}}
                                for f in event['DownloadAndChunkOutput'][1]['Output']['Filenames']
                            ]
                        }
            Handler: "index.handler"
            Runtime: "python3.6"
            Timeout: "30"
            Role: { "Fn::GetAtt" : [ "LambdaExecutionRole", "Arn" ] }
            FunctionName: { "Fn::Sub": "preprocessing-${Environment}-pipeline-prepare-sessionprocess2" }

    LambdaPrepareScoring:
        Type: "AWS::Lambda::Function"
        Properties:
            Code:
                ZipFile: !Sub |
                    def handler(event, context):
                        return {
                            "Meta": {
                                "ActivityArn": "${StepFunctionsActivity}",
                                "ExecutionArn": event['Meta']['ExecutionArn'],
                                "Environment": "${Environment}",
                                "NoopJobDefinition": "arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-definition/preprocessing-batchjob${BatchJobVersionNoop}"
                            },
                            "Branches": [
                                {
                                    "Resource": {
                                        "BatchJobQueue": "arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-queue/preprocessing-${Environment}-compute",
                                        "BatchJobDefinition": "arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-definition/preprocessing-batchjob${BatchJobVersionScoring}",
                                        "BatchJob": "scoring"
                                    },
                                    "InputPath": "$"
                                }
                            ],
                            "Input": {
                                **event["ReadDatabaseOutput"],
                                **{"Filenames": event['DownloadAndChunkOutput'][1]['Output']['Filenames']}
                            }
                        }
            Handler: "index.handler"
            Runtime: "python3.6"
            Timeout: "30"
            Role: { "Fn::GetAtt" : [ "LambdaExecutionRole", "Arn" ] }
            FunctionName: { "Fn::Sub": "preprocessing-${Environment}-pipeline-prepare-scoring" }

    LambdaWritePostgres:
        Type: "AWS::Lambda::Function"
        Properties:
            Code:
                ZipFile: !Sub |
                    import boto3, json
                    def handler(event, context):
                        lambda_client = boto3.client('lambda', region_name='us-west-2')
                        res = json.loads(lambda_client.invoke(
                            FunctionName='arn:aws:lambda:us-west-2:887689817172:function:preprocessing-dev-pipeline-querypostgres',
                            Payload=json.dumps({"Queries": [{
                                "Query": "UPDATE session_events SET session_success=True, updated_at = now() WHERE id = %s",
                                "Parameters": [event['ReadDatabaseOutput']['SessionEventId']]
                            }]}),
                        )['Payload'].read())
                        if res['Errors'][0] is not None:
                            raise Exception(res['Errors'][0])
                        return {}

            Handler: "index.handler"
            Runtime: "python3.6"
            Timeout: "30"
            Role: { "Fn::GetAtt" : [ "LambdaExecutionRole", "Arn" ] }
            FunctionName: { "Fn::Sub": "preprocessing-${Environment}-pipeline-writepostgres" }

    LambdaPrepareWriteMongo:
        Type: "AWS::Lambda::Function"
        Properties:
            Code:
                ZipFile: !Sub |
                    def handler(event, context):
                        return {
                            "Meta": {
                                "ActivityArn": "${StepFunctionsActivity}",
                                "ExecutionArn": event['Meta']['ExecutionArn'],
                                "Environment": "${Environment}",
                            },
                            "Branches": [
                                {
                                    "Resource": {
                                        "BatchJobQueue": "arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-queue/preprocessing-${Environment}-compute",
                                        "BatchJobDefinition": "arn:aws:batch:${AWS::Region}:${AWS::AccountId}:job-definition/preprocessing-batchjob${BatchJobVersionDatabaseupload}",
                                        "BatchJob": "writemongo"
                                    },
                                    "InputPath": "$"
                                }
                            ],
                            "Input": {
                                **event["ReadDatabaseOutput"],
                                **{"Filename": event['ScoringOutput'][1]['Output']['Filename']}
                            }
                        }
            Handler: "index.handler"
            Runtime: "python3.6"
            Timeout: "30"
            Role: { "Fn::GetAtt" : [ "LambdaExecutionRole", "Arn" ] }
            FunctionName: { "Fn::Sub": "preprocessing-${Environment}-pipeline-prepare-writemongo" }

    LambdaNotifySuccess:
        Type: "AWS::Lambda::Function"
        Properties:
            Code:
                ZipFile: !Sub |
                    def handler(event, context):
                        import boto3, os
                        sns_client = boto3.client('sns')
                        response = sns_client.publish(
                            TopicArn=os.environ['SNS_TOPIC'],
                            Message=event['SourceEvent']['S3Path'],
                        )
            Environment:
                Variables:
                    SNS_TOPIC: { Ref: "SnsSuccessTopic" }
            Handler: "index.handler"
            Runtime: "python3.6"
            Timeout: "30"
            Role: { "Fn::GetAtt" : [ "LambdaExecutionRole", "Arn" ] }
            FunctionName: { "Fn::Sub": "preprocessing-${Environment}-pipeline-notifysuccess" }

    ##########################################################################################################
    ##  LAMBDA
    ##########################################################################################################

    SnsSuccessTopic:
        Type: "AWS::SNS::Topic"
        Properties:
            DisplayName: "Biometrix preprocessing success notification"
            TopicName: { "Fn::Sub": "preprocessing-${Environment}-success" }

    ##########################################################################################################
    ##  STEP FUNCTIONS
    ##########################################################################################################

    StepFunctionsActivity:
        Type: "AWS::StepFunctions::Activity"
        Properties:
            Name: { "Fn::Sub": "preprocessing-${Environment}" }

    StateMachine:
        Type: "AWS::StepFunctions::StateMachine"
        Properties:
            DefinitionString: !Sub |
                {
                    "StartAt": "BuildDownloadAndChunkContext",
                    "States": {
                        "BuildDownloadAndChunkContext": {
                            "Type": "Task",
                            "Resource": "${LambdaPrepareDownloadAndChunk.Arn}",
                            "ResultPath": "$.DownloadAndChunkContext",
                            "Next": "DownloadAndChunk"
                        },
                        "DownloadAndChunk": {
                            "Type": "Parallel",
                            "Branches": [
                                {
                                    "StartAt": "ScheduleDownloadAndChunk",
                                    "States": {
                                        "ScheduleDownloadAndChunk": {
                                            "Type": "Task",
                                            "InputPath": "$.DownloadAndChunkContext",
                                            "Resource": "arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:preprocessing-sfn-batch-schedule",
                                            "End": true
                                        }
                                    }
                                },
                                {
                                    "StartAt": "RespondDownloadAndChunk",
                                    "States": {
                                        "RespondDownloadAndChunk": {
                                            "Type": "Task",
                                            "InputPath": "$.DownloadAndChunkContext",
                                            "Resource": "${StepFunctionsActivity}",
                                            "End": true
                                        }
                                    }
                                }
                            ],
                            "ResultPath": "$.DownloadAndChunkOutput",
                            "Next": "ReadDatabase"
                        },
                        "ReadDatabase": {
                            "Type": "Task",
                            "Resource": "${LambdaReadPostgres.Arn}",
                            "ResultPath": "$.ReadDatabaseOutput",
                            "Next": "BuildSessionProcess2Context"
                        },
                        "BuildSessionProcess2Context": {
                            "Type": "Task",
                            "Resource": "${LambdaPrepareSessionProcess2.Arn}",
                            "ResultPath": "$.SessionProcess2Context",
                            "Next": "SessionProcess2"
                        },
                        "SessionProcess2": {
                            "Type": "Parallel",
                            "Branches": [
                                {
                                    "StartAt": "ScheduleSessionProcess2",
                                    "States": {
                                        "ScheduleSessionProcess2": {
                                            "Type": "Task",
                                            "InputPath": "$.SessionProcess2Context",
                                            "Resource": "arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:preprocessing-sfn-batch-schedule",
                                            "End": true
                                        }
                                    }
                                },
                                {
                                    "StartAt": "RespondSessionProcess2",
                                    "States": {
                                        "RespondSessionProcess2": {
                                            "Type": "Task",
                                            "InputPath": "$.SessionProcess2Context",
                                            "Resource": "${StepFunctionsActivity}",
                                            "End": true
                                        }
                                    }
                                }
                            ],
                            "ResultPath": "$.SessionProcess2Output",
                            "Next": "BuildScoringContext"
                        },
                        "BuildScoringContext": {
                            "Type": "Task",
                            "Resource": "${LambdaPrepareScoring.Arn}",
                            "ResultPath": "$.ScoringContext",
                            "Next": "Scoring"
                        },
                        "Scoring": {
                            "Type": "Parallel",
                            "Branches": [
                                {
                                    "StartAt": "ScheduleScoring",
                                    "States": {
                                        "ScheduleScoring": {
                                            "Type": "Task",
                                            "InputPath": "$.ScoringContext",
                                            "Resource": "arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:preprocessing-sfn-batch-schedule",
                                            "End": true
                                        }
                                    }
                                },
                                {
                                    "StartAt": "RespondScoring",
                                    "States": {
                                        "RespondScoring": {
                                            "Type": "Task",
                                            "InputPath": "$.ScoringContext",
                                            "Resource": "${StepFunctionsActivity}",
                                            "End": true
                                        }
                                    }
                                }
                            ],
                            "ResultPath": "$.ScoringOutput",
                            "Next": "Upload"
                        },
                        "Upload": {
                            "Type": "Parallel",
                            "Branches": [
                                {
                                    "StartAt": "WritePostgres",
                                    "States": {
                                        "WritePostgres": {
                                            "Type": "Task",
                                            "Resource": "${LambdaWritePostgres.Arn}",
                                            "ResultPath": "$.WriteDatabaseOutput",
                                            "End": true
                                        }
                                    }
                                },
                                {
                                    "StartAt": "BuildWriteMongoContext",
                                    "States": {
                                        "BuildWriteMongoContext": {
                                            "Type": "Task",
                                            "Resource": "${LambdaPrepareWriteMongo.Arn}",
                                            "ResultPath": "$.WriteMongoContext",
                                            "Next": "WriteMongo"
                                        },
                                        "WriteMongo": {
                                            "Type": "Parallel",
                                            "Branches": [
                                                {
                                                    "StartAt": "ScheduleWriteMongo",
                                                    "States": {
                                                        "ScheduleWriteMongo": {
                                                            "Type": "Task",
                                                            "InputPath": "$.WriteMongoContext",
                                                            "Resource": "arn:aws:lambda:${AWS::Region}:${AWS::AccountId}:function:preprocessing-sfn-batch-schedule",
                                                            "End": true
                                                        }
                                                    }
                                                },
                                                {
                                                    "StartAt": "RespondWriteMongo",
                                                    "States": {
                                                        "RespondWriteMongo": {
                                                            "Type": "Task",
                                                            "InputPath": "$.WriteMongoContext",
                                                            "Resource": "${StepFunctionsActivity}",
                                                            "End": true
                                                        }
                                                    }
                                                }
                                            ],
                                            "ResultPath": "$.WriteMongoOutput",
                                            "End": true
                                        }
                                    }
                                }
                            ],
                            "ResultPath": "$.UploadOutput",
                            "Next": "Notify"
                        },
                        "Notify": {
                            "Type": "Task",
                            "Resource": "${LambdaNotifySuccess.Arn}",
                            "End": true
                        }
                    }
                }

            RoleArn: { "Fn::ImportValue" : "StepFunctionsServiceRole" }
