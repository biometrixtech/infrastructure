# A template that creates a code pipeline to create a new Docker image and register it to ECR
#
# Copyright 2016 Melon Software Ltd (UK), all rights reserved
#
AWSTemplateFormatVersion: "2010-09-09"
Description: "Creates a Code Pipeline to create a Job Definition with a new Docker image registered in ECR"

Parameters:

    GithubUser:
        Type: "String"
        Description: "Use an automation user rather than a personal user"
    GithubToken:
        Type: "String"
        Description: "See https://help.github.com/articles/creating-an-access-token-for-command-line-use/"
        NoEcho: true

    DefaultMemory:
        Type: "Number"
        Description: "Default memory allocation, in MB"

    DefaultVcpus:
        Type: "Number"
        Description: "Default number of vCPUs to use for this job"

Metadata:
    "AWS::CloudFormation::Interface":
        ParameterGroups:
          - Label: { default: "VCS Source" }
            Parameters:
              - "GithubUser"
              - "GithubToken"

        ParameterLabels:
            GithubUser: { default: "Username" }
            GithubToken: { default: "Access Token" }

Mappings:
    ServiceConfiguration:
        sessionprocess2:
            Cpu: 128
            Memory: 128
            Port: 80
            BuildSize: "BUILD_GENERAL1_SMALL"

Resources:

    ##########################################################################################################
    ## ECR
    ##########################################################################################################

    EcrRepository:
        Type: "AWS::ECR::Repository"
        Properties:
            RepositoryName: { "Fn::Sub": "preprocessing/batchjob" }

    ##########################################################################################################
    ##  IAM
    ##########################################################################################################

    JobRole:
        Type: "AWS::IAM::Role"
        Properties:
            AssumeRolePolicyDocument:
                Version: "2012-10-17"
                Statement:
                  - Effect: "Allow"
                    Principal: { Service: [ "ecs-tasks.amazonaws.com" ] }
                    Action: "sts:AssumeRole"
            Policies:
              - PolicyName: "default"
                PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Action:
                          - "s3:GetObject"
                          - "s3:PutObject"
                          - "s3:ListBucket"
                          - "states:SendTaskFailure"
                          - "states:SendTaskHeartbeat"
                          - "states:SendTaskSuccess"
                          - "sqs:DeleteMessage"
                        Effect: "Allow"
                        Resource: "*"
                      - Action:
                          - "ssm:DescribeParameters"
                          - "ssm:GetParameters"
                          - "kms:Decrypt"
                        Effect: "Allow"
                        Resource: "*" # TODO this should be segregated by environment somehow
                      - Action:
                          - "cloudwatch:PutMetricData"
                        Effect: "Allow"
                        Resource: "*"
            RoleName: { "Fn::Sub": "preprocessing-infrastructure-${AWS::Region}" }

    TriggerRole:
        Type: "AWS::IAM::Role"
        Properties:
            AssumeRolePolicyDocument:
                Version: "2012-10-17"
                Statement:
                  - Effect: "Allow"
                    Principal: { Service: [ "lambda.amazonaws.com" ] }
                    Action: "sts:AssumeRole"
            ManagedPolicyArns:
              - "arn:aws:iam::aws:policy/service-role/AWSLambdaVPCAccessExecutionRole"
            Policies:
              - PolicyName: "default"
                PolicyDocument:
                    Version: "2012-10-17"
                    Statement:
                      - Action:
                          - "codebuild:BatchGetBuilds"
                          - "codebuild:StartBuild"
                          - "ecr:ListImages"
                        Effect: "Allow"
                        Resource: "*"
            RoleName: { "Fn::Sub": "preprocessing-infrastructure-batchjob-trigger-${AWS::Region}" }

    ##########################################################################################################
    ##  CODEBUILD
    ##########################################################################################################

    CodeBuildProject:
        Type: "AWS::CodeBuild::Project"
        Properties:
            Name: { "Fn::Sub": 'preprocessing-batchjob' }
            Description: { "Fn::Sub": 'Builds a new Docker image for the Batch services and registers it to ECR' }
            ServiceRole: { "Fn::ImportValue": "CodeBuildServiceRole" }
            Artifacts:
                Type: "no_artifacts"
            Environment:
                Type: "linuxContainer"
                ComputeType: "BUILD_GENERAL1_SMALL"
                Image: "aws/codebuild/docker:1.12.1"
                EnvironmentVariables:
                  - { Name: "AWS_DEFAULT_REGION", Value: { Ref: "AWS::Region" } }
                  - { Name: "ECR_REGISTRY", Value: { "Fn::Sub": "${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com" } }
                  - { Name: "ECR_REPOSITORY", Value: { Ref: "EcrRepository" } }
                  - { Name: "JOB_ROLE_ARN", Value: { "Fn::GetAtt": [ "JobRole", "Arn" ] } }
                  - { Name: "DEFAULT_CPU", Value: { Ref : "DefaultVcpus" } }
                  - { Name: "DEFAULT_MEMORY", Value: { Ref : "DefaultMemory" } }
            TimeoutInMinutes: 30
            Tags:
              - { Key: "Name", Value: { "Fn::Sub": "preprocessing-batchjob" } }
              - { Key: "Management", Value: "managed" }
              - { Key: "Project", Value: "preprocessing" }
              - { Key: "Environment", Value: "infra" }
            Source:
                Location: { "Fn::Sub": 'https://${GithubUser}:${GithubToken}@github.com/biometrixtech/PreProcessing.git' }
                Type: "GITHUB"
                BuildSpec: |
                    version: 0.2
                    phases:
                        install:
                            commands:
                                # Upgrade AWS CLI
                              - pip install --upgrade --user awscli
                              - aws --version

                        pre_build:
                            commands:
                              - GIT_COMMIT=$(git rev-parse $CODEBUILD_SOURCE_VERSION)
                              - IMAGE_NAME=$ECR_REGISTRY/$ECR_REPOSITORY:$GIT_COMMIT

                                # Log in to the registry
                              - $(aws ecr get-login --region $AWS_DEFAULT_REGION)

                        build:
                            commands:
                                # Build the docker image
                              - docker build -f docker/preprocessing.docker -t $IMAGE_NAME .

                        post_build:
                            commands:

                                # Push the image to the docker registry
                              - docker push $IMAGE_NAME

                                # Create the job definition skeleton
                              - JOB_DEFINITION_NAME=preprocessing-batchjob
                              - 'echo "{
                                    \"jobDefinitionName\": \"$JOB_DEFINITION_NAME\",
                                    \"type\": \"container\",
                                    \"parameters\": { \"Meta\": \"{}\", \"Input\": \"{}\" },
                                    \"containerProperties\": {
                                        \"command\": [ \"Ref::Job\", \"Ref::Input\", \"Ref::Meta\" ],
                                        \"image\": \"$IMAGE_NAME\",
                                        \"jobRoleArn\": \"$JOB_ROLE_ARN\",
                                        \"memory\": $DEFAULT_MEMORY,
                                        \"privileged\": true,
                                        \"readonlyRootFilesystem\": false,
                                        \"vcpus\": $DEFAULT_CPU
                                    },
                                    \"retryStrategy\": {
                                        \"attempts\": 2
                                    }
                                }" > taskdefinition.json'
                              - cat taskdefinition.json

                              - aws batch register-job-definition --job-definition-name $JOB_DEFINITION_NAME --cli-input-json file://taskdefinition.json

    LambdaTrigger:
        Type: "AWS::Lambda::Function"
        Properties:
            Code:
                ZipFile: !Sub |
                    from botocore.vendored import requests
                    import json

                    SUCCESS = "SUCCESS"
                    FAILED = "FAILED"


                    def send(event, context, response_status, response_data=None, physical_resource_id=None):
                        response_url = event['ResponseURL']

                        print(response_url)

                        response_body = {}
                        response_body['Status'] = response_status
                        response_body['Reason'] = 'See the details in CloudWatch Log Stream: ' + context.log_stream_name
                        response_body['PhysicalResourceId'] = physical_resource_id or context.log_stream_name
                        response_body['StackId'] = event['StackId']
                        response_body['RequestId'] = event['RequestId']
                        response_body['LogicalResourceId'] = event['LogicalResourceId']
                        response_body['Data'] = response_data

                        json_response_body = json.dumps(response_body)

                        headers = {
                            'content-type': '',
                            'content-length': str(len(json_response_body))
                        }

                        try:
                            response = requests.put(response_url,
                                                    data=json_response_body,
                                                    headers=headers)
                            print("Status code: " + response.reason)
                        except Exception as e:
                            print("send(..) failed executing requests.put(..): " + str(e))

                    import logging
                    import boto3

                    logger = logging.getLogger()
                    logger.setLevel(logging.INFO)

                    def handler(event, context):
                        logger.info(event)
                        send(event, context, SUCCESS)

            Environment:
                Variables:
                    ECR_REGISTRY: { "Fn::Sub": "${AWS::AccountId}.dkr.ecr.${AWS::Region}.amazonaws.com" }
                    ECR_REPOSITORY: { Ref: "EcrRepository" }
            Handler: "index.handler"
            Runtime: "python3.6"
            Timeout: "300"
            Role: { "Fn::GetAtt" : [ "TriggerRole", "Arn" ] }
            FunctionName: { "Fn::Sub": "preprocessing-infrastructure-batchjob-trigger" }
            Tags:
              - { Key: "Name", Value: { "Fn::Sub": "preprocessing-infrastructure-batchjob-trigger" } }
              - { Key: "Management", Value: "managed" }
              - { Key: "Project", Value: "preprocessing" }
              - { Key: "Environment", Value: "infra" }
